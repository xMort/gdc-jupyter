{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, setup parameters about insight we want to work on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now prepare insight analyzer instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from insight_analyzer import *\n",
    "\n",
    "analyzer = ClusterAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are ready now. Let's get to work.\n",
    "First fetch the dataframe from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = analyzer.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's see the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Awesome! Now let's see them in a plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    df[df.columns[0]],\n",
    "    df[df.columns[1]]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ok, looks good. Let's set up our predictor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Threshold for cluster proximity, lower promotes splitting\n",
    "threshold = 0.03\n",
    "\n",
    "cluster_count = 3\n",
    "\n",
    "# We need to update our DF to be compatible with Birch\n",
    "x = np.column_stack((df[df.columns[0]], df[df.columns[1]]))\n",
    "\n",
    "model = Birch(threshold=threshold, n_clusters=cluster_count)\n",
    "yhat = model.fit_predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's preview the clusters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cluster in np.unique(yhat):\n",
    "    plt.scatter(df.values[yhat == cluster, 0], df.values[yhat == cluster, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Altough this looks promising, we will get better results, if we normalize the coordinates. To do so, let's use the `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normalized_df = scaler.fit_transform(df)\n",
    "normalized_df = pd.DataFrame(normalized_df, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ok, we can run our predictor again, with the same setting as before, so we do not change too much at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "# Threshold for cluster proximity, lower promotes splitting\n",
    "threshold = 0.03\n",
    "\n",
    "cluster_count = 3\n",
    "\n",
    "# We need to update our DF to be compatible with Birch\n",
    "x = np.column_stack(\n",
    "    (normalized_df[normalized_df.columns[0]],\n",
    "     normalized_df[normalized_df.columns[1]])\n",
    ")\n",
    "\n",
    "model = Birch(threshold=threshold, n_clusters=cluster_count)\n",
    "yhat = model.fit_predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "One last preview, before pushing the data to server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cluster in np.unique(yhat):\n",
    "    plt.scatter(df.values[yhat == cluster, 0], df.values[yhat == cluster, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Awesome! Last thing to do now is to push it to the server, so we can see it on our dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyzer.push_to_server(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gooddata",
   "language": "python",
   "name": "gooddata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
